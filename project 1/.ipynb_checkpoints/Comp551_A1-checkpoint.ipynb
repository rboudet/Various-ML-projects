{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1, 2) \n",
    "# run this cell by changing the value of the number of days\n",
    "\n",
    "def Q1_2(ndays):\n",
    "    count = [0, 0, 0, 0]\n",
    "    for i in range(ndays):\n",
    "        x = random.uniform(0, 1)\n",
    "        if x > 0.7:\n",
    "            count[3] = count[3] + 1\n",
    "            continue\n",
    "        if x > 0.6:\n",
    "            count[2] = count[2] + 1\n",
    "            continue\n",
    "        if x > 0.2:\n",
    "            count[1] = count[1] + 1\n",
    "            continue\n",
    "        count[0] = count[0] + 1\n",
    "    for i in range(len(count)):\n",
    "        count[i] = float(count[i]/ndays)\n",
    "    return count\n",
    "Q1_2(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchData(path):\n",
    "    # this method is used to fetch the data from the datasets folder and parse\n",
    "    # the X and Y values in seperate arrays\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            X.append((float)(row[0]))\n",
    "            Y.append((float)(row[1]))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method is used when plotting the fits of the polynomials\n",
    "\n",
    "def fittedPolynomial(weights, X):\n",
    "    values = []\n",
    "    for x in X:\n",
    "        value = 0\n",
    "        for i in range(21):\n",
    "            value += weights[i] * math.pow(x,i)\n",
    "        values.append(value)\n",
    "\n",
    "    return values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2 \n",
    "# 1)\n",
    "# a) and b) plotting\n",
    "\n",
    "def Q2_1_a():\n",
    "\n",
    "    # we want to train a 20-degree polynomial, with no regularization\n",
    "    trainX, trainY = fetchData(\"./Datasets/Dataset_1_train.csv\")\n",
    "    validX, validY = fetchData(\"./Datasets/Dataset_1_valid.csv\")\n",
    "\n",
    "    weights = np.ones(21)\n",
    "    np.transpose(weights)\n",
    "\n",
    "    # we want to create a data matrix\n",
    "    # the ith line will be the powers of x(i) from 0 to 20\n",
    "\n",
    "    # Data matrix will be for training, and DataMatrix2 for regularization\n",
    "    DataMatrix = []\n",
    "\n",
    "    # DataMatrix2 will be used to store all the validation data in same way we are storing the training data\n",
    "    DataMatrix2 = []\n",
    "\n",
    "    for i in range(len(trainX)):\n",
    "        temp = []\n",
    "        for k in range(21):\n",
    "            temp.append(math.pow(trainX[i], k))\n",
    "        DataMatrix.append(temp)\n",
    "\n",
    "    for i in range(len(validX)):\n",
    "        temp = []\n",
    "        for k in range(21):\n",
    "            temp.append(math.pow(validX[i], k))\n",
    "        DataMatrix2.append(temp)\n",
    "\n",
    "    X = np.array(DataMatrix)\n",
    "\n",
    "    # here we want to find the weights that minimizes the error function\n",
    "    # ie (X.T * X)^-1 * X.T * Y\n",
    "    inv = np.linalg.inv(np.matmul(X.T, X))\n",
    "    temp = np.matmul(inv, X.T)\n",
    "    finalWeights = np.matmul(temp, trainY)  # this is the updated weights for a 20 degree polynomial\n",
    "\n",
    "    # now we want to calculate the training error :\n",
    "    predictedResult = np.matmul(DataMatrix, finalWeights)\n",
    "\n",
    "    trainingError = 0\n",
    "    for i in range(len(predictedResult)):\n",
    "        trainingError = trainingError + math.pow(trainY[i] - predictedResult[i], 2)\n",
    "    trainingError = trainingError / len(predictedResult)\n",
    "\n",
    "\n",
    "    validError = 0\n",
    "    predictedResult = np.matmul(DataMatrix2, finalWeights)\n",
    "    for i in range(len(validX)):\n",
    "        validError = validError + math.pow(validY[i] - predictedResult[i], 2)\n",
    "\n",
    "    validError = validError / len(predictedResult)\n",
    "    \n",
    "    plt.title(\"Fitting with 20 degree polynomial, no regularization\")\n",
    "    plt.plot(trainX, trainY, 'go') #actual data points\n",
    "\n",
    "    trainX = np.sort(trainX)\n",
    "    T = np.arange(trainX[0], trainX[len(trainX) - 1], 0.001)\n",
    "    plt.plot(T, fittedPolynomial(finalWeights, T))\n",
    "\n",
    "    plt.legend(['Data points', 'polynomial fitted'])\n",
    "    plt.show()\n",
    "\n",
    "    return {\"trainingError\":trainingError, \"validationError\":validError}\n",
    "\n",
    "Q2_1_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method trains a 20 degree polynomial with regularization, where the 'lambda' value\n",
    "# used is the parameter taken by the method\n",
    "\n",
    "def train20degPolyWithReg(value):\n",
    "\n",
    "    # we want to train a 20-degree polynomial, with no regularization\n",
    "    # we want to create a data matrix\n",
    "    # the ith line will be the powers of x(i) from 0 to 20\n",
    "    trainX, trainY = fetchData(\"./Datasets/Dataset_1_train.csv\")\n",
    "    validX, validY = fetchData(\"./Datasets/Dataset_1_valid.csv\")\n",
    "    testX, testY = fetchData(\"./Datasets/Dataset_1_test.csv\")\n",
    "\n",
    "    trainingData = []\n",
    "    validData = []\n",
    "    testData = []\n",
    "\n",
    "    for i in range(len(trainX)):\n",
    "        temp = []\n",
    "        for k in range(21):\n",
    "            temp.append(math.pow(trainX[i], k))\n",
    "        trainingData.append(temp)\n",
    "\n",
    "    for i in range(len(validX)):\n",
    "        temp = []\n",
    "        for k in range(21):\n",
    "            temp.append(math.pow(validX[i], k))\n",
    "        validData.append(temp)\n",
    "\n",
    "    for i in range(len(testX)):\n",
    "        temp = []\n",
    "        for k in range(21):\n",
    "            temp.append(math.pow(testX[i], k))\n",
    "        testData.append(temp)\n",
    "\n",
    "    X = np.array(trainingData)\n",
    "\n",
    "    # We want to find the weights that minimize the error function (now containing the regularization parameter)\n",
    "\n",
    "    lambdaMatrix = value * 20 * np.identity(21)\n",
    "    inv = np.linalg.inv(np.matmul(X.T, X) + lambdaMatrix)\n",
    "    temp = np.matmul(inv, X.T)\n",
    "    final = np.matmul(temp, trainY) # this is the updated weights for a 20 degree polynomial\n",
    "    normOfWeights = 0\n",
    "    for i in range(len(final)):\n",
    "        normOfWeights += math.pow(final[i], 2)\n",
    "\n",
    "    # now we want to calculate the training error :\n",
    "    predictedResult = np.matmul(trainingData, final)\n",
    "    trainingError = 0\n",
    "    for i in range(len(predictedResult)):\n",
    "        trainingError += math.pow(trainY[i] - predictedResult[i], 2)\n",
    "    trainingError = trainingError / len(predictedResult) + value * 0.5 * normOfWeights\n",
    "\n",
    "    validError = 0\n",
    "    predictedResult = np.matmul(validData, final)\n",
    "    for i in range(len(validX)):\n",
    "        validError = validError + math.pow(validY[i] - predictedResult[i], 2)\n",
    "\n",
    "    validError = validError / len(predictedResult) + value * 0.5 * normOfWeights\n",
    "\n",
    "    testError = 0\n",
    "    predictedResult = np.matmul(testData, final)\n",
    "    for i in range(len(testX)):\n",
    "        testError = testError + math.pow(validY[i] - predictedResult[i], 2)\n",
    "\n",
    "    testError = testError / len(predictedResult) + value * 0.5 * normOfWeights\n",
    "    \n",
    "    return final, trainingError, validError, testError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "# 2)\n",
    "# a)\n",
    "\n",
    "def Q2_2_a():\n",
    "    #this method will test different values of lambda and plot the training errors and validation errors\n",
    "    T = np.arange(0,1,0.01)\n",
    "    training = []\n",
    "    validation = []\n",
    "    errorForLambdaValue = {}\n",
    "    for value in T:\n",
    "        weights,trainingError,validError,testError = train20degPolyWithReg(value)\n",
    "        training.append(trainingError)\n",
    "        validation.append(validError)\n",
    "        errorForLambdaValue[value] = validError\n",
    "\n",
    "    # now we want to plot training error and validation error against lambda\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.plot(T, training, 'k')\n",
    "    plt.xlabel(\"value of lambda\")\n",
    "    plt.ylabel(\"value of training error\")\n",
    "    plt.subplot(212)\n",
    "    plt.plot(T, validation,'k')\n",
    "    plt.xlabel(\"value of lambda\")\n",
    "    plt.ylabel(\"value of validation error\")\n",
    "    plt.show()\n",
    "\n",
    "    return errorForLambdaValue\n",
    "\n",
    "Q2_2_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def regressionWithGradientDescent(alpha):\n",
    "    trainX, trainY = fetchData(\"./Datasets/Dataset_2_train.csv\")\n",
    "    validX, validY = fetchData(\"./Datasets/Dataset_2_valid.csv\")\n",
    "    testX, testY = fetchData(\"./Datasets/Dataset_2_test.csv\")\n",
    "\n",
    "    plt.plot(trainX, trainY, 'ro')\n",
    "\n",
    "    validMSE = []\n",
    "    trainingMSE = []\n",
    "    testMSE = []\n",
    "    epoch = []\n",
    "    w0 = 1\n",
    "    w1 = 1\n",
    "\n",
    "\n",
    "    # we want to iterate through values of alpha and decide\n",
    "    # which is the best value depending on validation MSE\n",
    "\n",
    "    predictionsPerEpoch = []  # this will keep track of the fits after every epoch\n",
    "    k = 0\n",
    "    while True:\n",
    "        T = np.arange(0,len(trainX))\n",
    "        np.random.shuffle(T)  # we shuffle the order in which we go through the data points\n",
    "        epoch.append(k)\n",
    "        w0_old = w0  # we keep track of the old weights, in order to have a stop parameter\n",
    "        w1_old = w1\n",
    "\n",
    "        # we go through every element of the training set, and update the weights\n",
    "        for i in T:\n",
    "            guess = w0 + trainX[i]*w1\n",
    "            w0 = w0 - alpha*(guess-trainY[i])\n",
    "            w1 = w1 - alpha*(guess - trainY[i])*trainX[i]\n",
    "\n",
    "        X = np.array(trainX)\n",
    "        Y_values = w0 + X*w1\n",
    "        predictionsPerEpoch.append(Y_values)\n",
    "\n",
    "        # here we calculate the MSE for this epoch\n",
    "        error = 0\n",
    "        for i in range(len(validX)):\n",
    "            guess = w0 + validX[i]*w1\n",
    "            error += math.pow((guess - validY[i]), 2)\n",
    "        validMSE.append(error/len(validY))\n",
    "        error = 0\n",
    "\n",
    "        for i in range(len(trainX)):\n",
    "            guess = w0 + trainX[i]*w1\n",
    "            error += math.pow((guess - trainY[i]), 2)\n",
    "        trainingMSE.append(error/len(trainX))\n",
    "\n",
    "        error = 0\n",
    "        for i in range(len(testX)):\n",
    "            guess = w0 + testX[i] * w1\n",
    "            error += math.pow((guess - testY[i]), 2)\n",
    "        testMSE.append(error / len(testX))\n",
    "\n",
    "        if k > 10000:\n",
    "            # this check is to prevent models from diverging (ie when alpha is too large)\n",
    "            print(\"stopped\")\n",
    "            break\n",
    "\n",
    "        # we stop if the the error does not change more thant 10^-4\n",
    "        if len(validMSE) > 2 and math.fabs(validMSE[len(validMSE)-1] - validMSE[len(validMSE)-2]) < math.pow(10,-4):\n",
    "            break\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    return epoch, validMSE, trainingMSE, testMSE, predictionsPerEpoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 \n",
    "# 1)\n",
    "# a)\n",
    "\n",
    "def Q3_1_a():\n",
    "    epoch, validMSE, trainingMSE, testMSE, fits = regressionWithGradientDescent(math.pow(10, -6))\n",
    "    print(\"all MSE on validation set after each epoch\")\n",
    "    return validMSE\n",
    "\n",
    "Q3_1_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 \n",
    "# 1)\n",
    "# b)\n",
    "\n",
    "def Q3_1_b():\n",
    "    # here we compute the validation error for each epoch\n",
    "\n",
    "    epoch, validMSE, trainingMSE, testMSE, fits = regressionWithGradientDescent(math.pow(10, -6))\n",
    "\n",
    "    # and we then plot the training error and the validation error for each epoch\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(\"plots of Training and Validation error for every iteration\")\n",
    "    plt.ylabel(\"Validation error\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.plot(epoch, validMSE, 'k')\n",
    "    plt.subplot(212)\n",
    "    plt.ylabel(\"training error\")\n",
    "    plt.plot(epoch, trainingMSE, 'k')\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()\n",
    "\n",
    "Q3_1_b()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 \n",
    "# 2)\n",
    "# b)\n",
    "\n",
    "def Q3_2_b():\n",
    "    # In this method, we will go through different values of alpha\n",
    "    # and select the one that minimizes the validation MSE\n",
    "\n",
    "    alpha = math.pow(10, -6)\n",
    "    file = open(\"alpha_validMSE.txt\", \"w\")  # we use this file to store the MSE for all different values of alpha\n",
    "    minValidationError = 1\n",
    "    associatedTestError = 0\n",
    "    alphaValue = 0\n",
    "    predictionsForAlphaValue = []\n",
    "    while alpha < 0.5:\n",
    "        epoch, validMSE, trainingMSE, testMSE, predictions = regressionWithGradientDescent(alpha)\n",
    "        # we find the minimal validation MSE error found\n",
    "        index = np.argmin(validMSE)\n",
    "        if validMSE[index] < minValidationError:\n",
    "            minValidationError = validMSE[index]\n",
    "            associatedTestError = testMSE[index]\n",
    "            alphaValue = alpha\n",
    "            predictionsForAlphaValue = predictions\n",
    "\n",
    "        file.write(str(alpha) + \" --  \" + str(validMSE))\n",
    "        file.write('\\n')\n",
    "        alpha = alpha * 2\n",
    "        # if alpha > 0.01:\n",
    "        #     alpha = alpha * 1.5\n",
    "        # else:\n",
    "        #     alpha = alpha * 2\n",
    "    file.close()\n",
    "\n",
    "    print(\"smallest validation mse was found for alpha value : \")\n",
    "    print(alphaValue)\n",
    "    # and we want to get the test error for this specific value of alpha\n",
    "    print(\"the corresponding test error is :\")\n",
    "    print(associatedTestError)\n",
    "\n",
    "    # and we return all the predictions found after each epoch using this specific alpha value\n",
    "    return predictionsForAlphaValue\n",
    "\n",
    "Q3_2_b()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3 \n",
    "# 3)\n",
    "\n",
    "def Q3_3():\n",
    "    # this method will produce 2 subplots :\n",
    "    # 1) the fit after every epoch\n",
    "    # 2) 5 randomly chosen fits to show the progression of the fit\n",
    "    trainX, trainY = fetchData(\"./Datasets/Dataset_2_train.csv\")\n",
    "    predictionsForAlphaValue = Q3_2_b()\n",
    "\n",
    "    plt.subplot(211)\n",
    "    plt.title(\"Plot of the linear regression fit after every epoch\")\n",
    "    plt.plot(trainX,trainY, 'ro')\n",
    "    for i in range(len(predictionsForAlphaValue)):\n",
    "        plt.plot(trainX, predictionsForAlphaValue[i])\n",
    "\n",
    "    plt.subplot(212)\n",
    "    plt.title(\"5 randomly chosen linear regression fits during gradient descent training\")\n",
    "    plt.plot(trainX,trainY, 'ro')\n",
    "    legends = [\"training data\"]\n",
    "    for i in range(5):\n",
    "        index1 = random.randint(0, len(predictionsForAlphaValue)-1)\n",
    "        plt.plot(trainX, predictionsForAlphaValue[index1])\n",
    "        del predictionsForAlphaValue[index1]\n",
    "        legends.append(\"fit after \" + str(index1) + \"iterations\")\n",
    "\n",
    "\n",
    "    plt.xlabel(\"X values\")\n",
    "    plt.ylabel(\"Y values\")\n",
    "    plt.legend(legends)\n",
    "    plt.show()\n",
    "    \n",
    "Q3_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "# 1)\n",
    "# a)\n",
    "\n",
    "\n",
    "def Q4_1_a():\n",
    "    # need to fetch the data and update the missing values with the sample mean of each column\n",
    "\n",
    "    dataMatrix = []\n",
    "    with open('./communities.data.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            dataMatrix.append(row)\n",
    "\n",
    "    # now we're going to fetch the sample mean of each column (except the 4rd column as it is the comunity name)\n",
    "    sampleMeans = []\n",
    "    sampleMedians = []\n",
    "    for i in range(len(dataMatrix[0])):\n",
    "        if i == 3:  # 4th column\n",
    "            continue\n",
    "        temp = 0\n",
    "        counter = 0\n",
    "        column = []\n",
    "        for k in range(len(dataMatrix)):\n",
    "            if dataMatrix[k][i] != '?':\n",
    "                column.append(float(dataMatrix[k][i]))\n",
    "                temp += float(dataMatrix[k][i])\n",
    "                counter += 1\n",
    "        column = np.sort(column)\n",
    "        sampleMedians.append(column[int(len(column)/2)])\n",
    "        sampleMeans.append(temp/counter)\n",
    "\n",
    "    # now we replace each '?' with the sample median from that column\n",
    "    for i in range(len(dataMatrix[0])):\n",
    "        if i == 3:\n",
    "            continue\n",
    "        for k in range(len(dataMatrix)):\n",
    "            if dataMatrix[k][i] == '?':\n",
    "                # dataMatrix[k][i] = sampleMeans[i]\n",
    "                dataMatrix[k][i] = sampleMedians[i]\n",
    "    file = open(\"completedData.csv\", 'w')\n",
    "    writer = csv.writer(file)\n",
    "    for k in range(len(dataMatrix)):\n",
    "        writer.writerow(dataMatrix[k])\n",
    "    file.close()\n",
    "\n",
    "Q4_1_a()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper method to create and store the 80-20 splits\n",
    "\n",
    "def create80_20Split(data):\n",
    "    cutoff = int(0.8*len(data))\n",
    "    for i in range(5):\n",
    "        # we also remove the first 5 columns as they are not used for prediction\n",
    "        np.random.shuffle(data)\n",
    "        training = data[:cutoff-1]\n",
    "        test = data[cutoff:]\n",
    "        file = open(\"CandC-train\" + str(i+1) + \".csv\", 'w')\n",
    "        writer = csv.writer(file)\n",
    "        for row in training:\n",
    "            writer.writerow(row[5:])\n",
    "        file.close()\n",
    "\n",
    "        file = open(\"CandC-test\" + str(i+1) + \".csv\", 'w')\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # we remove the first 5 columns, as they are not used for prediction\n",
    "        for row in test:\n",
    "            writer.writerow(row[5:])\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to perform a linear regression with lambda value as parameter\n",
    "\n",
    "\n",
    "def linearRegression(value):\n",
    "    # this method will be used to fit a model to the data present in the CandC sets\n",
    "    # it takes as parameter the Lambda value for regularization ( 0 in case of no regularization)\n",
    "\n",
    "    # for each 80- 20 data set, we want to fit a linear model and calculate\n",
    "    # the MSE for the corresponding test set\n",
    "    errorSum = 0\n",
    "    weights = []\n",
    "    for i in range(5):\n",
    "        trainingX = []\n",
    "        trainingY = []\n",
    "        testX = []\n",
    "        testY = []\n",
    "        file = open(\"CandC-train\" + str(i+1) + \".csv\", 'r')\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            temp = []\n",
    "            for k in range(len(row) - 1):\n",
    "                temp.append(float(row[k]))\n",
    "            trainingX.append(temp)\n",
    "            trainingY.append(float(row[len(row) - 1]))  # the 'Y' element is present on the last column\n",
    "        file.close()\n",
    "        file = open(\"CandC-test\" + str(i+1) + \".csv\", 'r')\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            temp = []\n",
    "            for k in range(len(row) - 1):\n",
    "                temp.append(float(row[k]))\n",
    "            testX.append(temp)\n",
    "            testY.append(float(row[len(row) - 1]))\n",
    "\n",
    "        X = np.array(trainingX)\n",
    "        inv = np.linalg.inv(np.matmul(X.T, X) + value*np.identity(len(X.T)))\n",
    "        temp = np.matmul(inv, X.T)\n",
    "        finalW = np.matmul(temp, trainingY)\n",
    "        weights.append(finalW)  # we add the weights of the model for the ith split\n",
    "\n",
    "        # now we want to calculate the MSE of the test error\n",
    "        totalError = 0\n",
    "        for k in range(len(testX)):\n",
    "            prediction = np.matmul(testX[k], finalW)\n",
    "            totalError += math.pow(prediction - testY[k], 2)\n",
    "        errorSum += totalError/len(testX)\n",
    "        # we store the error value found fot this lambda value\n",
    "\n",
    "    # and we average it out over the 5 splits\n",
    "\n",
    "    averageError = errorSum/5\n",
    "\n",
    "    # we return the weights that have been learned for each of the splits and the average error associated\n",
    "\n",
    "    return weights, averageError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error found for linear regression w/o regularization : \n",
      "0.021258208960518072\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# 2)\n",
    "\n",
    "def Q4_2():\n",
    "    # we go fetch the completed data\n",
    "    dataMatrix = []\n",
    "    with open('./completedData.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            dataMatrix.append(row)\n",
    "\n",
    "    create80_20Split(dataMatrix)  # if the splits have not been created we recreate them\n",
    "    weights, error = linearRegression(0)  # we then call the linearRegression method with a lambda value of 0\n",
    "    print(\"average error found for linear regression w/o regularization : \")\n",
    "    print(error)\n",
    "\n",
    "Q4_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min error is : 0.020906899582078836\n",
      "obtained at lambda : 0.9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 4\n",
    "# 3)\n",
    "# a)\n",
    "\n",
    "def Q4_3_a(plotGraph = True, dataIsSet=False):\n",
    "    # the 2 optional parameters are here in order to be able to reuse the code\n",
    "    # in this method without performing some of the tasks (ie recreate the splits)\n",
    "    # or plot a certain graph\n",
    "    \n",
    "    if not(dataIsSet):\n",
    "        data = []\n",
    "        with open('./completedData.csv', 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "\n",
    "        create80_20Split(data)  # if the splits have not been created we recreate them\n",
    "    T = np.arange(0, 1, 0.05)  # these will be the lambda value we will be testing on\n",
    "    tempMin = 1\n",
    "    valueForMin = 0\n",
    "    weightsForMin = []\n",
    "    errors = []\n",
    "    for value in T:\n",
    "        weights, error = linearRegression(value)\n",
    "        errors.append(error)\n",
    "        if error < tempMin:\n",
    "            tempMin = error\n",
    "            valueForMin = value\n",
    "            weightsForMin = weights\n",
    "\n",
    "    print(\"min error is : \" + str(tempMin))\n",
    "    print(\"obtained at lambda : \" + str(valueForMin))\n",
    "    if plotGraph:\n",
    "        # and then we plot the average errors obtained for each of the lambda values tested\n",
    "        plt.title(\"plot of average MSE for different regularization values with feature selection\")\n",
    "        plt.plot(T, errors, 'ro')\n",
    "        plt.xlabel(\"lambda value\")\n",
    "        plt.ylabel(\"average error\")\n",
    "        plt.show()\n",
    "    file = open(\"weightsForMinValue.csv\", 'w')\n",
    "    writer = csv.writer(file)\n",
    "    for i in range(len(weightsForMin)):\n",
    "        writer.writerow(weightsForMin[i])\n",
    "    file.close()\n",
    "    #each row will represent the weights for one of the 5 slipts\n",
    "    \n",
    "    # and we return the lambda value that lead to the lowest error, along with the weights associated\n",
    "    return valueForMin\n",
    "\n",
    "Q4_3_a()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "# 3)\n",
    "# c)\n",
    "\n",
    "def Q4_3_c():\n",
    "\n",
    "    # we fetch the weights of the model that will be selected\n",
    "    # we pass the original data (which gets completed by the Q4_1_a() method\n",
    "    value = Q4_3_a(plotGraph=False)\n",
    "    \n",
    "    w = []\n",
    "    # we go fetch the weights that we stored in a csv file\n",
    "    file = open(\"weightsForMinValue.csv\", 'r')\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        temp = []\n",
    "        for k in range(len(row)):\n",
    "            temp.append(float(row[k]))\n",
    "        w.append(temp)\n",
    "\n",
    "    # Then we choose which features we want to keep\n",
    "    featuresToKeep = []\n",
    "    weights = np.array(w)\n",
    "    # here weights is an array of the 5 different weights of the models, take the one that had the smallest error?\n",
    "    sumOfWeights = np.sum(weights, axis=0)\n",
    "    for j in range(len(sumOfWeights)):\n",
    "        if math.fabs(sumOfWeights[j]/5) > 0.05 :\n",
    "            featuresToKeep.append(j + 5)  # to take in account the first 5 columns we had removed previously\n",
    "\n",
    "    # Then we go to the completed data and keep only those features, storing all this in a new csv file\n",
    "    print(\"kept \" + str(len(featuresToKeep)) + \" features\")\n",
    "    file = open('completedData.csv', 'r')\n",
    "    file2 = open('selectedFeatures.csv', 'w')\n",
    "    writer = csv.writer(file2)\n",
    "    reader = csv.reader(file)\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        tempRow = []\n",
    "        for k in range(len(row)):\n",
    "            if k in featuresToKeep:\n",
    "                tempRow.append(row[k])\n",
    "        data.append(tempRow)\n",
    "        writer.writerow(tempRow)\n",
    "    file.close()\n",
    "    file2.close()\n",
    "\n",
    "    # and now we can test the model with the selected features by\n",
    "    # calling the regression method and passing the updated data\n",
    "    # this will print the minimal error found and will plot the the values of errors depending on lambda\n",
    "\n",
    "    # we first create the 5 80-20 splits of the new data\n",
    "    create80_20Split(data)\n",
    "\n",
    "    # and then we call the linear regression method, passing the 'best' lambda value found previously\n",
    "    Q4_3_a(dataIsSet=True)\n",
    "\n",
    "Q4_3_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
